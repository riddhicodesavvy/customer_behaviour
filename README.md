

Customer Shopping Behavior: End-to-End Data Analysis Project
üìå Project Overview
This project focuses on analyzing customer shopping patterns to derive actionable insights for retail businesses. The workflow covers the entire data lifecycle: from raw data cleaning and transformation in Python, storage and querying in PostgreSQL, to interactive data visualization in Power BI.
üõ†Ô∏è Tech Stack
‚Ä¢	Language: Python 3.x
‚Ä¢	Libraries: Pandas, NumPy, SQLAlchemy, Psycopg2
‚Ä¢	Database: PostgreSQL
‚Ä¢	Visualization: Power BI
‚Ä¢	Environment: Jupyter Notebook
üìÇ Dataset Description
The dataset contains 3,900 records of customer transactions, including:
‚Ä¢	Demographics: Age, Gender, Location.
‚Ä¢	Transaction Details: Item Purchased, Category, Purchase Amount (USD), Season.
‚Ä¢	Customer Loyalty: Subscription Status, Previous Purchases, Frequency of Purchases.
‚Ä¢	Feedback: Review Ratings.
________________________________________
‚öôÔ∏è Data Pipeline
1. Data Cleaning & Transformation (Python)
Using Pandas in a Jupyter Notebook, I performed the following steps to ensure data quality and readiness for SQL:
‚Ä¢	Missing Value Treatment: Identified null values in Review Rating and imputed them using the median rating of their respective product categories.
‚Ä¢	Standardization: Converted column names to lowercase and replaced spaces with underscores (e.g., Purchase Amount (USD) ‚Üí purchase_amount) for seamless SQL integration.
‚Ä¢	Feature Engineering:
o	Age Grouping: Categorized customers into Young Adult, Adult, Middle-aged, and Senior using quantile-based binning (pd.qcut).
o	Frequency Mapping: Converted categorical frequency (e.g., "Weekly", "Fortnightly") into numeric purchase_frequency_days for quantitative analysis.
‚Ä¢	Redundancy Removal: Dropped columns like promo_code_used that didn't add unique value to the analysis.

2. Database Management (PostgreSQL)
After cleaning, the data was exported to a PostgreSQL database using the SQLAlchemy engine.
‚Ä¢	Workflow: Automated the table creation and data insertion process from Python.
‚Ä¢	SQL Analysis: Executed queries to identify high-value customers, regional sales trends, and seasonal performance.
‚Ä¢	Sample Query: ```sql SELECT category, SUM(purchase_amount) as total_sales FROM customer GROUP BY category ORDER BY total_sales DESC;
‚Ä¢	
3. Data Visualization (Power BI)
The PostgreSQL database was connected to Power BI to create a dynamic dashboard. Key visuals include:
‚Ä¢	Sales Overview: Total Revenue ($233k) and Total Purchases.
‚Ä¢	Category Performance: Analysis showing Clothing as the lead revenue generator ($104k+).
‚Ä¢	Customer Segmentation: Breakdown of spending by Gender and Age Group.
‚Ä¢	Regional Insights: A map visualization showing top-performing states.
________________________________________
üìà Key Insights
‚Ä¢	Top Category: Clothing is the most popular and profitable category, followed by Accessories.
‚Ä¢	Customer Demographics: Spending is remarkably balanced between Male and Female customers, suggesting a broad market appeal.
‚Ä¢	Age Trends: The "Young Adult" segment represents a significant portion of the customer base, followed closely by "Middle-aged" shoppers.
‚Ä¢	Revenue: The total generated revenue from the analyzed period stands at $233,081.
üöÄ How to Run
1.	Python: Run the customer_behaviour.ipynb to clean the data and push it to your local PostgreSQL instance.
2.	SQL: Use the customer table in PostgreSQL to run analytical queries.
3.	Power BI: Open customer_behaviour_visuals.pbix and refresh the data source to see the updated visuals (ensure your PostgreSQL service is running).





________________________________________
üìù Final Thoughts
This project demonstrates a robust understanding of the data engineering and analysis process. By moving data from a flat file (CSV) to a relational database (SQL) and finally to a BI tool, I've created a scalable solution for business intelligence.
________________________________________


 

	


